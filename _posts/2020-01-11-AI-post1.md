---
layout: post
title: "AI 필기장 - 1. CNN"
date: 2020-01-06 15:50:00
categories: AI
---
* * *

# CNN(Convolution Neural Network) - 합성곱 신경망

주요 키워드 : **필터** = 학습시킬 가중치, **패딩** = 데이터의 크기가 합성곱으로 인해 줄어드는 것을 방지하기 위해 0을 채워 넣는 것,  
**스트라이드** = 필터가 몇 칸씩 넘기며 연산할 지 정하는 것. -> 합성곱 계층에선 패딩과 스트라이드로 출력 데이터의 크기를 조절한다.

보통 합성곱 계층에선 입력 데이터와 출력 데이터의 크기를 동일하게 하고, 풀링 계층에서 출력 데이터를 줄여 연산량을 감소시킨다.

채널 : 특징 맵(Feature Map)으로 걸러진(해당 특징이 부각된) 출력 맵 한 장 -> 필터마다 하나의 채널이 만들어진다.

풀링 : 특정 크기의 맵을 하나의 값으로 바꾸는 작업.(최대 or 최소 or 평균)
특징 - 1. 학습할 매개 변수가 없다. = 단순한 계산 작업
       2. 채널마다 독립적으로 계산하기 때문에 채널 수에 변화가 없다.
       3. 맵의 대푯값이므로 입력의 변화에 적게 영향을 받는다.

CNN의 차원 수 = 4차원 : data[데이터 수][채널 수][픽셀 x][픽셀 y]

**필터를 적용한다** 라는 개념이 이론적으론 쉽지만 실제 구현 시에는 필터를 적용할 때마다 일일히 해당 인덱스를 찾아 연산하기란 쉽지 않다.  
따라서 실제 구현 시엔 4차원의 데이터를 필터를 적용하기 쉽게 2차원 배열로 바꾸어 행렬곱 연산을 수행할 수 있게 해준다.

합성곱 계층 구현 -  

im2col 함수 : 이미지 데이터(4차원)를 입력받아 필터와의 계산을 2차원 행렬곱으로 수행하기 위해 바꿔주는 함수.
ret[필터가 적용된 수][필터를 한 번 적용할 때 필요한 연산의 수 = 필터 크기 x 채널 수]

풀링 계층 구현 -  
합성곱 계층과 비슷하게 im2col 함수를 통해 필터를 적용하듯이 펼쳐준다. 단, 풀링 계층에선 채널들마다 연산을 해줘야 한다.

AlexNet의 LRN(Local Response Normalization) - AlexNet은 ReLu 함수를 사용하였기 때문에 양수방향으로 값이 무한정으로 커질 수 있다는 단점이
있었다.  가중치의 값이 너무 커지면 주변의 픽셀값들을 무시해버릴 수 있기 때문에 같은 픽셀 위치의 다른 필터 값과 비교해 정규화해주는 과정이
LRN 이다.  